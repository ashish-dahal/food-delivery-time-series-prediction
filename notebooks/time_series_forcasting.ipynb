{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Preliminary Data Exploration** ðŸ“ŠðŸ”\n",
    "\n",
    "Getting a feel for the data is an important first step. This is where we can start to understand the data and identify any potential issues. We can also start to think about how we might want to structure our data for modeling. For the assignment, this step will help in choosing a modeling approach ðŸ¤”ðŸ’¡."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "original_df = pd.read_csv('../data/orders_autumn_2020.csv')\n",
    "\n",
    "# Create a copy of the original dataframe\n",
    "df = original_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check columns and data types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ðŸ” Observation:** There are 18706 data points in the dataset with 13 features. Also, there seems to be some missing values in the dataset ðŸš«ðŸ“‰."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ðŸ” Observation**: Some values for the weather ðŸŒ¤ï¸ features are missing. We will have to handle these missing values (impute, drop) if we decide to use these features depending on our model (some models handle missing data natively).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ðŸ” Observation**: There are no duplicate data points in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get statistical summary of the dataset\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ðŸ” Observations**: \n",
    "- â±ï¸ The data indicates a generally efficient delivery system, with actual delivery times often being less than estimated.\n",
    "- ðŸŒ¦ï¸ The weather conditions show notable variation, which could impact delivery times.\n",
    "- ðŸ—ºï¸ The proximity of users to venues (latitude, longitude) suggests a densely populated or urban area, possibly leading to quicker deliveries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Check how the dataset looks like\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Modeling Approach** ðŸ¤–ðŸ“ˆ\n",
    "\n",
    "After getting a feel of the data, and taking into account what I have learnt about Wolt's business model, the following modeling approach is chosen:\n",
    "\n",
    "### **ðŸ”® \"What would be the order demand for the next day?\"** \n",
    "\n",
    "### **Motivations for the modeling approach:**\n",
    "Accurate forecasting of item demand helps Wolt's business model in the following ways:\n",
    "\n",
    "- ðŸ’¼ **Resource Management:** Ensures optimal allocation of delivery personnel and reduces operational costs. \n",
    "\n",
    "- ðŸ‘©â€ðŸ³ **Partner Restaurants Efficiency:** Helps restaurants prepare for demand, improving food quality and reducing waste. \n",
    "\n",
    "- ðŸ’° **Dynamic Pricing:** Enables effective dynamic pricing and promotional strategies to manage demand. \n",
    "\n",
    "- ðŸ“ˆ **Financial Planning:** Essential for revenue forecasting and strategic decisions, like market expansion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Exploratory Data Analysis**\n",
    "\n",
    "- Trend and Seasonality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "from haversine import haversine, Unit\n",
    "from geopy.distance import geodesic\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seaborn style in Wolt brand colors\n",
    "wolt_colors = [\"#004C5C\", \"#FF007A\", \"#56C1E6\"]  # Dark Blue, Pink, Light Blue\n",
    "\n",
    "# Set the theme with a Wolt color palette\n",
    "sns.set_theme(style=\"whitegrid\", palette=sns.color_palette(wolt_colors))\n",
    "\n",
    "# Further customize\n",
    "plt.rcParams[\"axes.spines.top\"] = False\n",
    "plt.rcParams[\"axes.spines.right\"] = False\n",
    "plt.rcParams[\"axes.spines.left\"] = True\n",
    "plt.rcParams[\"axes.spines.bottom\"] = True\n",
    "plt.rcParams[\"grid.color\"] = \"#eeeeee\"\n",
    "plt.rcParams[\"grid.linestyle\"] = \"-\"\n",
    "plt.rcParams[\"grid.linewidth\"] = 0.75\n",
    "plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "plt.rcParams[\"axes.edgecolor\"] = \"#333333\"\n",
    "\n",
    "# set figure size\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the TIMESTAMP column to datetime format\n",
    "df['TIMESTAMP'] = pd.to_datetime(df['TIMESTAMP'])\n",
    "\n",
    "# Make TIMESTAMP the index of the dataframe as it will easy to group by date\n",
    "df.set_index('TIMESTAMP', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to calculate the distance between two latitude and longitude points\n",
    "def calculate_distance(lat1: float, lon1: float, lat2: float, lon2: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the distance between latitude and longitude points\n",
    "\n",
    "    Args:\n",
    "        lat1 (float): Latitude of first point\n",
    "        lon1 (float): Longitude of first point\n",
    "        lat2 (float): Latitude of second point\n",
    "        lon2 (float): Longitude of second point\n",
    "    \n",
    "    Returns:\n",
    "        float: Distance between two points in kilometers\n",
    "    \"\"\"\n",
    "    # return haversine((lat1, lon1), (lat2, lon2), unit=Unit.KILOMETERS)\n",
    "    return geodesic((lat1, lon1), (lat2, lon2)).km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the distance from latitude and longitude of user and venue\n",
    "df['DISTANCE'] = df.apply(lambda x: calculate_distance(x['USER_LAT'], x['USER_LONG'], x['VENUE_LAT'], x['VENUE_LONG']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distance column\n",
    "df['DISTANCE'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(matrix: np.ndarray, title: str) -> None:\n",
    "    \"\"\"\n",
    "    Plot a heatmap\n",
    "\n",
    "    Args:\n",
    "        matrix (numpy.ndarray): Matrix to plot\n",
    "        title (str): Title of the heatmap\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    sns.heatmap(\n",
    "        data = matrix, \n",
    "        annot=True,\n",
    "        linewidth = 0.5, \n",
    "        cmap=sns.light_palette(wolt_colors[2], as_cmap=True),\n",
    "    )\n",
    "\n",
    "    plt.title(title, fontsize=18, fontweight='bold')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the correlation between relevant columns\n",
    "relevant_columns = ['ITEM_COUNT', 'ESTIMATED_DELIVERY_MINUTES', 'ACTUAL_DELIVERY_MINUTES', \n",
    "                   'CLOUD_COVERAGE', 'TEMPERATURE', 'WIND_SPEED', 'PRECIPITATION', 'DISTANCE']\n",
    "plot_heatmap(df[relevant_columns].corr(), 'Correlation Heatmap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Model Selection**\n",
    "\n",
    "Given the nature of the data, timeseries forecasting models are a good choice. The data is a time series of item demand, and we want to predict the demand for the next day.\n",
    "\n",
    "> ### **Following models are considered for the approach:**\n",
    "\n",
    "- **ðŸ“‰ SARIMAX (Baseline):** It is a good baseline model for our data as it has seasionality and external factors. It is also relatively easy to interpret and explain the results than blackbox models.\n",
    "\n",
    "- ðŸš€ **XGBoost:** XGBoost is a powerful ensemble machine learning model that can handle both regression and timeseries forecasting tasks. It can capture complex patterns and dependencies in the data. \n",
    "\n",
    "- **ðŸ§  LSTM:** LSTM is a good choice for timeseries forecasting, and can be used to capture the non-linearities in the data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new DataFrame with daily frequency and number of orders\n",
    "daily_orders = df.resample('D').size()\n",
    "\n",
    "daily_orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_line(df: pd.DataFrame, title: str, xlabel, ylabel, size=None) -> None:\n",
    "    \"\"\"\n",
    "    Plot a line chart\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe to plot the line chart for\n",
    "        title (str): Title of the chart\n",
    "        xlabel (str): Label of the x-axis\n",
    "        ylabel (str): Label of the y-axis\n",
    "        size (tuple): Size of the chart\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    sns.lineplot(\n",
    "        data=daily_orders, \n",
    "        color=wolt_colors[2]\n",
    "    )\n",
    "    plt.title(title, fontsize=18, fontweight='bold')\n",
    "    plt.xlabel(xlabel, fontsize=14)\n",
    "    plt.ylabel(ylabel, fontsize=14)\n",
    "    if size:\n",
    "        plt.figure(figsize=size)\n",
    "    plt.show()\n",
    "\n",
    "plot_line(df, title='Daily Orders', xlabel='Date', ylabel='Number of Orders', size=(15, 12))\n",
    "plot_line(df, title='Daily Orders', xlabel='Date', ylabel='Number of Orders', size=(15, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Feature Engineering**\n",
    "\n",
    "- hourly, daily and weekly decomposition\n",
    "- calculate distance between venue and delivery location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.1 SARIMAX (Baseline)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.2 XGBoost**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.3 LSTM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8. Further Development**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
